{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we will do an implementation of the neural network language model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN architecture\n",
    "\n",
    "The architecture of the Forward Neural Network. \n",
    "\n",
    "* $n$ context size\n",
    "* $m$ the number of features associated with each word (ex: m = 100, Each word is represented by a vector of size 100).\n",
    "* $C$ is size $|V|\\times m$\n",
    "\n",
    "$$y = b + Wx + U\\tanh(d + Hx)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $x = (C(w_{t-1}), C(w_{t-2}), \\ldots, C(w_{t-n+1}))$, vector of size $m\\times(n-1)$\n",
    "* $h$ be the number of hidden units\n",
    "* $H$ Corresponds to the dense layer. $H$ has $m\\times(n-1)$ columns and $h$ rows\n",
    "* $d$ Corresponds to the dense layer. $d$ is a vector of size $h$\n",
    "* $U$ Corresponds to the second dense layer. $U$ has $h$ columns $|V|$ lines\n",
    "* W dense **(can be equal to zero)**\n",
    "* $b$ vector of size $|V|$ \n",
    "\n",
    "\n",
    "Total number of parameters\n",
    "\n",
    "$ |V |(1 + nm + h) + h(1 + (n − 1)m)$\n",
    "\n",
    "Input data\n",
    "=====\n",
    "\n",
    "For n=4\n",
    "\n",
    "$$D = [(2, 10, 3, 5), (8, 30, 2, 20), ...]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from utility import text_preprocessing, create_unique_word_dict\n",
    "import csv \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a|a'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "m = 10\n",
    "sizeV = 5\n",
    "C = np.random.randn(sizeV, m)\n",
    "a=\"ca|ca\"\n",
    "for i in range(len(a)):\n",
    "    print(i)\n",
    "a.replace(a[0],\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"http://arxiv.org/abs/1303.6933v1|Hans Grauert (1930-2011)|Alan Huckleberry|math.HO|Hans Grauert died in September of 2011. This article reviews his life in mathematics and recalls some detail his major accomplishments.|2013-03-27T19:23:57Z|2013-03-27T19:23:57Z|math\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hans Grauert (1930-2011) Hans Grauert died in September of 2011. This article reviews his life in mathematics and recalls some detail his major accomplishments.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.split('|')[1]+' '+ a.split('|')[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C[[2, 4, 3], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[[1, 2,4], [0,3, 4]]\n",
    "temp = C[X, :]\n",
    "#print(temp)\n",
    "nb_features=10\n",
    "result = np.reshape(temp, (np.shape(X)[0], m * np.shape(X)[1]))\n",
    "print(np.shape(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "C = np.random.randn(4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.ravel(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2, 3],[0,2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.reshape(C[X,:],(np.shape(X)[0],10*np.shape(X)[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape((np.concatenate(C[X, :])),(2,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.concatenate(C[:, np.concatenate(X)]).reshape((X.shape[0], X.shape[1]*C.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(C[:, np.concatenate(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Project_and_concat() : \n",
    "    \"\"\"\n",
    "    The input is a vector x = (w_{t-1}, w_{t-2}, ..., w_{t-n+1})\n",
    "    For example, for n=4 the input vector x can be\n",
    "    (4, 2, 10)\n",
    "    where 4, 2 and 10 are the indexes of the corresponding words.\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_features,dict_size) : # V*m ou m*V\n",
    "        self.nb_features = nb_features\n",
    "        self.dict_size = dict_size\n",
    "        self.C = np.random.randn(dict_size,nb_features)\n",
    "        self.nb_params = nb_features * dict_size # Nombre de parametres de la couche\n",
    "        self.save_X = None # Parametre de sauvegarde des donnees\n",
    "    def set_params(self,params) : \n",
    "        # Permet de modifier les parametres de la couche, en entree, prend un vecteur de la taille self.nb_params\n",
    "        pass\n",
    "    def get_params(self) : \n",
    "        # Rend un vecteur de taille self.params qui contient les parametres de la couche\n",
    "        return np.ravel(self.C)\n",
    "    def forward(self,X) : \n",
    "        # calcul du forward, X est le vecteur des donnees d'entrees\n",
    "        self.save_X = np.copy(X)\n",
    "        return np.ravel(np.concatenate(C[X, :]))\n",
    "    def backward(self,grad_sortie) :  \n",
    "        # retropropagation du gradient sur la couche, \n",
    "        #grad_sortie est le vecteur du gradient en sortie\n",
    "        #Cette fonction rend :\n",
    "        #grad_local, un vecteur de taille self.nb_params qui contient le gradient par rapport aux parametres locaux\n",
    "        #grad_entree, le gradient en entree de la couche \n",
    "        grad_local=None\n",
    "        grad_entree=np.reshape(grad_sortie,(dict_size,nb_features))\n",
    "        return grad_local,grad_entree\n",
    "        \n",
    "# 2 étapes dans cette couche, les selections des lignes de C puis la concaténation\n",
    "# est ce que la selection des lignes de C rentre dans le calcul du dradient d'entree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(np.ones(4), np.concatenate(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([[1,2,3],[4,5,6]])\n",
    "b=np.array([2,3,4])\n",
    "\n",
    "a=np.exp(a)\n",
    "s=np.sum(a,axis=1)\n",
    "print(a)\n",
    "print(a.T)\n",
    "print(s)\n",
    "print(a.T/s)\n",
    "print(np.sum(a.T/s,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([[1,2,3],[4,5,6]])\n",
    "b=np.array([1,2,3])\n",
    "\n",
    "print(np.sum(a,axis=0))\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(np.sum(a,axis=0))\n",
    "\n",
    "print(np.exp(a)/np.sum(np.exp(a),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Neuralword as Neur\n",
    "\n",
    "print(np.shape(a))\n",
    "print((Neur.ilogit(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=np.array([-5,-7,-10])\n",
    "np.argmax(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
