{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we will do an implementation of the neural network language model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN architecture\n",
    "\n",
    "The architecture of the Forward Neural Network. \n",
    "\n",
    "* $n$ context size\n",
    "* $m$ the number of features associated with each word (ex: m = 100, Each word is represented by a vector of size 100).\n",
    "* $C$ is size $|V|\\times m$\n",
    "\n",
    "$$y = b + Wx + U\\tanh(d + Hx)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $x = (C(w_{t-1}), C(w_{t-2}), \\ldots, C(w_{t-n+1}))$, vector of size $m\\times(n-1)$\n",
    "* $h$ be the number of hidden units\n",
    "* $H$ Corresponds to the dense layer. $H$ has $m\\times(n-1)$ columns and $h$ rows\n",
    "* $d$ Corresponds to the dense layer. $d$ is a vector of size $h$\n",
    "* $U$ Corresponds to the second dense layer. $U$ has $h$ columns $|V|$ lines\n",
    "* W dense **(can be equal to zero)**\n",
    "* $b$ vector of size $|V|$ \n",
    "\n",
    "\n",
    "Total number of parameters\n",
    "\n",
    "$ |V |(1 + nm + h) + h(1 + (n − 1)m)$\n",
    "\n",
    "Input data\n",
    "=====\n",
    "\n",
    "For n=4\n",
    "\n",
    "$$D = [(2, 10, 3, 5), (8, 30, 2, 20), ...]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from utility import text_preprocessing, create_unique_word_dict\n",
    "import csv \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a|a'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "m = 10\n",
    "sizeV = 5\n",
    "C = np.random.randn(sizeV, m)\n",
    "a=\"ca|ca\"\n",
    "for i in range(len(a)):\n",
    "    print(i)\n",
    "a.replace(a[0],\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"http://arxiv.org/abs/1303.6933v1|Hans Grauert (1930-2011)|Alan Huckleberry|math.HO|Hans Grauert died in September of 2011. This article reviews his life in mathematics and recalls some detail his major accomplishments.|2013-03-27T19:23:57Z|2013-03-27T19:23:57Z|math\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 30: expected 5 fields, saw 8\\nSkipping line 46: expected 5 fields, saw 8\\nSkipping line 54: expected 5 fields, saw 6\\nSkipping line 64: expected 5 fields, saw 12\\nSkipping line 71: expected 5 fields, saw 6\\nSkipping line 86: expected 5 fields, saw 8\\nSkipping line 106: expected 5 fields, saw 9\\nSkipping line 115: expected 5 fields, saw 6\\nSkipping line 126: expected 5 fields, saw 6\\nSkipping line 132: expected 5 fields, saw 7\\nSkipping line 134: expected 5 fields, saw 7\\nSkipping line 136: expected 5 fields, saw 6\\nSkipping line 169: expected 5 fields, saw 7\\nSkipping line 190: expected 5 fields, saw 6\\nSkipping line 199: expected 5 fields, saw 7\\nSkipping line 203: expected 5 fields, saw 11\\nSkipping line 208: expected 5 fields, saw 6\\nSkipping line 215: expected 5 fields, saw 6\\nSkipping line 217: expected 5 fields, saw 7\\nSkipping line 227: expected 5 fields, saw 7\\nSkipping line 230: expected 5 fields, saw 6\\nSkipping line 242: expected 5 fields, saw 6\\nSkipping line 251: expected 5 fields, saw 8\\nSkipping line 254: expected 5 fields, saw 6\\nSkipping line 279: expected 5 fields, saw 7\\nSkipping line 286: expected 5 fields, saw 6\\nSkipping line 305: expected 5 fields, saw 7\\nSkipping line 314: expected 5 fields, saw 10\\nSkipping line 326: expected 5 fields, saw 7\\nSkipping line 331: expected 5 fields, saw 6\\nSkipping line 344: expected 5 fields, saw 6\\nSkipping line 348: expected 5 fields, saw 6\\nSkipping line 361: expected 5 fields, saw 7\\nSkipping line 380: expected 5 fields, saw 6\\nSkipping line 385: expected 5 fields, saw 9\\nSkipping line 403: expected 5 fields, saw 6\\nSkipping line 411: expected 5 fields, saw 10\\nSkipping line 413: expected 5 fields, saw 8\\nSkipping line 435: expected 5 fields, saw 8\\nSkipping line 439: expected 5 fields, saw 6\\nSkipping line 440: expected 5 fields, saw 6\\nSkipping line 444: expected 5 fields, saw 7\\nSkipping line 458: expected 5 fields, saw 10\\nSkipping line 466: expected 5 fields, saw 8\\nSkipping line 468: expected 5 fields, saw 7\\nSkipping line 473: expected 5 fields, saw 6\\nSkipping line 477: expected 5 fields, saw 6\\nSkipping line 478: expected 5 fields, saw 6\\nSkipping line 483: expected 5 fields, saw 6\\nSkipping line 499: expected 5 fields, saw 7\\nSkipping line 535: expected 5 fields, saw 7\\nSkipping line 541: expected 5 fields, saw 6\\nSkipping line 560: expected 5 fields, saw 12\\nSkipping line 566: expected 5 fields, saw 6\\nSkipping line 570: expected 5 fields, saw 8\\nSkipping line 577: expected 5 fields, saw 10\\nSkipping line 579: expected 5 fields, saw 6\\nSkipping line 585: expected 5 fields, saw 9\\nSkipping line 587: expected 5 fields, saw 6\\nSkipping line 588: expected 5 fields, saw 6\\nSkipping line 590: expected 5 fields, saw 7\\nSkipping line 595: expected 5 fields, saw 6\\nSkipping line 599: expected 5 fields, saw 9\\nSkipping line 600: expected 5 fields, saw 7\\nSkipping line 601: expected 5 fields, saw 9\\nSkipping line 602: expected 5 fields, saw 7\\nSkipping line 609: expected 5 fields, saw 7\\nSkipping line 610: expected 5 fields, saw 13\\nSkipping line 611: expected 5 fields, saw 12\\nSkipping line 616: expected 5 fields, saw 6\\nSkipping line 622: expected 5 fields, saw 8\\nSkipping line 626: expected 5 fields, saw 13\\nSkipping line 627: expected 5 fields, saw 7\\nSkipping line 629: expected 5 fields, saw 7\\nSkipping line 634: expected 5 fields, saw 7\\nSkipping line 637: expected 5 fields, saw 13\\nSkipping line 639: expected 5 fields, saw 16\\nSkipping line 640: expected 5 fields, saw 12\\nSkipping line 646: expected 5 fields, saw 6\\nSkipping line 658: expected 5 fields, saw 9\\nSkipping line 669: expected 5 fields, saw 12\\nSkipping line 680: expected 5 fields, saw 9\\nSkipping line 689: expected 5 fields, saw 6\\nSkipping line 715: expected 5 fields, saw 6\\nSkipping line 718: expected 5 fields, saw 7\\nSkipping line 719: expected 5 fields, saw 6\\nSkipping line 729: expected 5 fields, saw 7\\nSkipping line 734: expected 5 fields, saw 9\\nSkipping line 735: expected 5 fields, saw 6\\nSkipping line 740: expected 5 fields, saw 12\\nSkipping line 741: expected 5 fields, saw 8\\nSkipping line 742: expected 5 fields, saw 7\\nSkipping line 749: expected 5 fields, saw 10\\nSkipping line 750: expected 5 fields, saw 6\\nSkipping line 752: expected 5 fields, saw 9\\nSkipping line 757: expected 5 fields, saw 6\\nSkipping line 760: expected 5 fields, saw 10\\nSkipping line 761: expected 5 fields, saw 10\\nSkipping line 762: expected 5 fields, saw 6\\nSkipping line 764: expected 5 fields, saw 6\\nSkipping line 767: expected 5 fields, saw 7\\nSkipping line 772: expected 5 fields, saw 6\\nSkipping line 793: expected 5 fields, saw 6\\nSkipping line 795: expected 5 fields, saw 6\\nSkipping line 799: expected 5 fields, saw 12\\nSkipping line 803: expected 5 fields, saw 9\\nSkipping line 809: expected 5 fields, saw 7\\nSkipping line 811: expected 5 fields, saw 6\\nSkipping line 813: expected 5 fields, saw 6\\nSkipping line 822: expected 5 fields, saw 7\\nSkipping line 825: expected 5 fields, saw 12\\nSkipping line 831: expected 5 fields, saw 7\\nSkipping line 832: expected 5 fields, saw 13\\nSkipping line 834: expected 5 fields, saw 12\\nSkipping line 835: expected 5 fields, saw 6\\nSkipping line 837: expected 5 fields, saw 6\\nSkipping line 841: expected 5 fields, saw 9\\nSkipping line 843: expected 5 fields, saw 11\\nSkipping line 844: expected 5 fields, saw 8\\nSkipping line 846: expected 5 fields, saw 7\\nSkipping line 847: expected 5 fields, saw 7\\nSkipping line 850: expected 5 fields, saw 6\\nSkipping line 853: expected 5 fields, saw 8\\nSkipping line 854: expected 5 fields, saw 9\\nSkipping line 855: expected 5 fields, saw 7\\nSkipping line 856: expected 5 fields, saw 16\\nSkipping line 861: expected 5 fields, saw 6\\nSkipping line 862: expected 5 fields, saw 6\\nSkipping line 863: expected 5 fields, saw 8\\nSkipping line 864: expected 5 fields, saw 13\\nSkipping line 872: expected 5 fields, saw 9\\nSkipping line 873: expected 5 fields, saw 11\\nSkipping line 882: expected 5 fields, saw 6\\nSkipping line 883: expected 5 fields, saw 7\\nSkipping line 884: expected 5 fields, saw 7\\nSkipping line 885: expected 5 fields, saw 17\\nSkipping line 886: expected 5 fields, saw 9\\nSkipping line 887: expected 5 fields, saw 6\\nSkipping line 888: expected 5 fields, saw 13\\nSkipping line 893: expected 5 fields, saw 15\\nSkipping line 896: expected 5 fields, saw 13\\nSkipping line 897: expected 5 fields, saw 13\\nSkipping line 898: expected 5 fields, saw 11\\nSkipping line 899: expected 5 fields, saw 11\\nSkipping line 900: expected 5 fields, saw 17\\nSkipping line 901: expected 5 fields, saw 6\\nSkipping line 903: expected 5 fields, saw 8\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2017] that every essentially countable equivalence relation that is induced by an action of abelian non-archimedean Polish group is essentially hyperfinite.|2020-01-16T15:09:02Z|2020-01-16T15:09:02Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' independent of the dimension of the hypercube.|2018-08-28T18:32:05Z|2018-08-28T18:32:05Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' can be extended from continuous maps between locally compact Hausdorff spaces to separated locally proper maps between arbitrary topological spaces.|2014-04-30T08:35:41Z|2014-11-05T20:38:23Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' then the iterations of these operators applied to suitable convex bodies sequentially converge in the Hausdorff distance to fixed points.|2019-11-11T19:37:23Z|2019-11-11T19:37:23Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' the symmetric group $S_5$.|2018-01-09T14:18:00Z|2018-01-17T15:21:24Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' the intersection lattice of Discriminantal arrangement.|2018-02-26T05:07:15Z|2018-02-26T05:07:15Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' and small perturbations thereof.|2019-11-27T17:52:31Z|2019-11-27T17:52:31Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' the random graph product of a sequence of finite groups is a rational duality group with probability tending to 1 as n goes to infinity. This includes random right angled Coxeter groups as a special case.|2012-10-16T21:07:41Z|2013-11-21T18:47:36Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' thereby revealing free extra structure that is not apparent from the definitions. This also leads to precise characterizations of these theories in the form of universal properties.|2016-09-27T22:08:38Z|2016-09-27T22:08:38Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' to show that there is a Martin-L\\\\\"of random set X such that X does not compute 0\\' and X computes every K-trivial set.|2013-04-09T20:25:47Z|2013-04-09T20:25:47Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' we suggest variations of these games for further study.|2010-03-23T19:20:26Z|2010-03-23T19:20:26Z',\n",
       " nan,\n",
       " ' and conjectured $v(d)\\\\leq d^{cd}$. We confirm it.|2015-03-25T18:55:08Z|2015-03-25T18:55:08Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' generalising the one-dimensional result where $A$ is just a self-adjoint operator. This is done using almost analytic extensions and the higher-dimensional Helffer-Sj\\\\\"ostrand formula.|2012-01-16T10:34:58Z|2012-01-16T10:34:58Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' that appear as first return maps of hyperbolic polycycles. Here we solve the problem of realization of these moduli.|2019-10-14T13:22:16Z|2019-10-14T13:22:16Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' and use this to prove the vanishing of tautological classes for many bundles with fibre an aspherical manifold.|2017-05-17T16:09:15Z|2019-11-26T20:42:27Z',\n",
       " nan,\n",
       " nan,\n",
       " ' 2017]. This study is devoted to their further investigation and to generalization of the abstract Lagrange multiplier rule from [3].|2017-12-05T09:36:05Z|2017-12-05T09:36:05Z',\n",
       " nan,\n",
       " nan,\n",
       " ' we cannot rule out the possibility of the group $\\\\mathbb{Z}/16\\\\mathbb{Z}$ appearing as a torsion group of an elliptic curve.|2018-06-15T14:19:03Z|2018-07-25T11:56:37Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' with dim A bounded by a constant depending only on p.|2003-03-12T15:39:37Z|2003-05-12T15:51:49Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " \" as well as the uniform boundedness conjecture (Merel's theorem).|1995-06-01T01:02:11Z|1995-06-01T01:02:11Z\",\n",
       " ' but the fine structure depends on conjectures on birational classification of algebraic varieties. Serious applications of the Lang map are still being searched.|1995-12-23T19:26:37Z|1995-12-23T19:26:37Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' and open problems (all issues).|2003-04-07T17:08:36Z|2003-04-07T17:08:36Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' and Thomas establish a \"transfer principle\" by means of which the Euclidean distance degree of an orthogonally-stable matrix variety can be computed from the Euclidean distance degree of its intersection with a linear subspace. We generalise this principle.|2017-08-25T11:37:45Z|2018-01-17T13:40:14Z',\n",
       " ' and introduce a natural condition which guarantees that they do.|1998-04-20T15:50:54Z|1998-04-20T15:50:54Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' it is to say that the group of symplectic diffeomorphisms is C^0-closed in the group of all diffeomorphisms.|2007-03-12T12:23:17Z|2007-07-20T14:51:34Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' and the corresponding partition functions.   The observation adds new view-point also to the problem of finding intertwining operators by which isospectral pairs of metrics with different local geometries on compact submanifolds can be constructed. Among the examples the author constructed the most surprising are the isospectrality families containing both homogeneous and locally inhomogeneous metrics. The observation provides even quantum physical interpretation to the isospectrality.|2006-02-21T18:35:45Z|2006-02-21T18:35:45Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' a substitute for the Lie bracket given by the antisymmetrization of the pre-Lie product.|2014-06-03T19:25:07Z|2014-06-03T19:25:07Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' we get a solution for the steady compressible Euler equations of fluid dynamics. We also introduce a renormalization process to obtain solutions for Euler equations from non-$C^2$ isometric embeddings of the flat torus. Extensions to multi-dimensions are discussed.|2018-11-05T03:53:31Z|2018-11-05T03:53:31Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' unlike previous papers on the same topic.|2012-08-03T10:58:50Z|2012-08-03T10:58:50Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " \" analogous to finite \\\\'etale extensions in algebraic geometry.|2014-08-11T20:00:12Z|2015-11-13T11:43:22Z\",\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' our construction also gives a large class of simple transitive $2$-representations in infinite dihedral type for general bipartite graphs.|2016-09-04T17:26:03Z|2018-12-02T21:50:50Z',\n",
       " ' simple transitive $2$-representations corresponding to tricolored generalized $\\\\mathsf{ADE}$ Dynkin diagrams.|2018-04-24T09:26:36Z|2019-06-19T06:17:53Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " \" or of Joyal's cellular sets.|2014-05-31T09:02:44Z|2014-05-31T09:02:44Z\",\n",
       " nan,\n",
       " nan,\n",
       " ' $E_8$.|2011-10-25T16:52:34Z|2015-03-23T21:33:07Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' inverse semigroup algebras and Leavitt path algebras. In this paper we show that the category of unitary $\\\\Bbbk\\\\mathscr G$-modules is equivalent to the category of sheaves of $\\\\Bbbk$-modules over $\\\\mathscr G$. As a consequence we obtain a new proof of a recent result that Morita equivalent groupoids have Morita equivalent algebras.|2014-05-31T16:01:13Z|2014-05-31T16:01:13Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' and we finally present an application to Banach space theory.|2012-06-05T00:00:30Z|2013-05-10T22:05:55Z',\n",
       " nan,\n",
       " ' 47 pages].|2012-05-03T20:46:31Z|2012-09-15T06:42:15Z',\n",
       " nan,\n",
       " ' it follows that these schemes are glicci. We describe the biliaisons explicitely in the proof of the main theorem.|2005-05-19T16:05:51Z|2006-12-13T13:37:59Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' and how geography influences these mechanisms.|2019-06-21T04:54:04Z|2019-06-21T04:54:04Z',\n",
       " ' which allows for automatic detection and correction of structural faults.|2003-09-17T03:49:05Z|2003-09-17T03:49:05Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' that we apply to the modeling of an international patenting process as a working example.|2009-07-07T15:29:58Z|2009-07-07T15:29:58Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' and to show its application for knowledge representation by giving a typology of definitional knowledge.|2000-03-07T15:44:08Z|2000-03-07T15:44:08Z',\n",
       " ' 2014. Racing 2014 was co-located with the IEEE European Test Symposium (ETS).|2014-05-08T07:09:55Z|2014-05-08T07:09:55Z',\n",
       " nan,\n",
       " nan,\n",
       " ' we consider some potential solutions for addressing described problems.|2018-10-02T20:01:43Z|2018-10-02T20:01:43Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' but grows as the author encounters new items. Contributions are very welcome!|2012-05-23T09:52:40Z|2012-05-23T09:52:40Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' mouse-oriented user interface.|2015-07-14T00:51:45Z|2015-07-14T00:51:45Z',\n",
       " nan,\n",
       " nan,\n",
       " \" '2-SAT deletion'. The status of fixed-parameter tractability of this problem is a long-standing open question in the area of Parameterized Complexity. We resolve this open question by proposing an algorithm which solves this problem in $O(15^k*k*m^3)$ and thus we show that this problem is fixed-parameter tractable.|2008-01-08T19:04:14Z|2008-04-18T14:07:04Z\",\n",
       " ' we verify that our approach outperforms relevant baselines and is able to navigate in both seen and unseen environments.|2019-03-01T18:16:03Z|2019-03-01T18:16:03Z',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ' we identify major factors contributing to the successful deployment of a SMM.|2019-08-27T12:17:23Z|2019-08-27T12:17:23Z',\n",
       " nan,\n",
       " nan,\n",
       " ' in both classification and prediction of cognates.   Source code is at: https://github.com/pranav-ust/cognates|2018-11-20T08:59:53Z|2018-11-20T08:59:53Z',\n",
       " nan,\n",
       " ' is presented.|2006-05-08T12:21:51Z|2006-05-08T12:21:51Z',\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=pd.read_csv(\"input/arxiv_test.csv\",error_bad_lines=False)\n",
    "texts = [x for x in texts['text']]\n",
    "#for i in range(len(texts)):\n",
    "#    texts[i]=(texts[i].split('|'))[4]\n",
    "    \n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76405235  0.40015721  0.97873798  2.2408932   1.86755799 -0.97727788\n",
      "   0.95008842 -0.15135721 -0.10321885  0.4105985 ]\n",
      " [ 0.14404357  1.45427351  0.76103773  0.12167502  0.44386323  0.33367433\n",
      "   1.49407907 -0.20515826  0.3130677  -0.85409574]\n",
      " [-2.55298982  0.6536186   0.8644362  -0.74216502  2.26975462 -1.45436567\n",
      "   0.04575852 -0.18718385  1.53277921  1.46935877]\n",
      " [ 0.15494743  0.37816252 -0.88778575 -1.98079647 -0.34791215  0.15634897\n",
      "   1.23029068  1.20237985 -0.38732682 -0.30230275]\n",
      " [-1.04855297 -1.42001794 -1.70627019  1.9507754  -0.50965218 -0.4380743\n",
      "  -1.25279536  0.77749036 -1.61389785 -0.21274028]]\n"
     ]
    }
   ],
   "source": [
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.55298982,  0.6536186 ,  0.8644362 , -0.74216502,  2.26975462,\n",
       "        -1.45436567,  0.04575852, -0.18718385,  1.53277921,  1.46935877],\n",
       "       [-1.04855297, -1.42001794, -1.70627019,  1.9507754 , -0.50965218,\n",
       "        -0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028],\n",
       "       [ 0.15494743,  0.37816252, -0.88778575, -1.98079647, -0.34791215,\n",
       "         0.15634897,  1.23029068,  1.20237985, -0.38732682, -0.30230275]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[[2, 4, 3], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 30)\n"
     ]
    }
   ],
   "source": [
    "X=[[1, 2,4], [0,3, 4]]\n",
    "temp = C[X, :]\n",
    "#print(temp)\n",
    "nb_features=10\n",
    "result = np.reshape(temp, (np.shape(X)[0], m * np.shape(X)[1]))\n",
    "print(np.shape(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "C = np.random.randn(4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.ravel(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2, 3],[0,2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.reshape(C[X,:],(np.shape(X)[0],10*np.shape(X)[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323,\n",
       "         0.33367433,  1.49407907, -0.20515826,  0.3130677 , -0.85409574,\n",
       "        -2.55298982,  0.6536186 ,  0.8644362 , -0.74216502,  2.26975462,\n",
       "        -1.45436567,  0.04575852, -0.18718385,  1.53277921,  1.46935877,\n",
       "         0.15494743,  0.37816252, -0.88778575, -1.98079647, -0.34791215,\n",
       "         0.15634897,  1.23029068,  1.20237985, -0.38732682, -0.30230275],\n",
       "       [ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799,\n",
       "        -0.97727788,  0.95008842, -0.15135721, -0.10321885,  0.4105985 ,\n",
       "        -2.55298982,  0.6536186 ,  0.8644362 , -0.74216502,  2.26975462,\n",
       "        -1.45436567,  0.04575852, -0.18718385,  1.53277921,  1.46935877,\n",
       "         0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323,\n",
       "         0.33367433,  1.49407907, -0.20515826,  0.3130677 , -0.85409574]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape((np.concatenate(C[X, :])),(2,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.concatenate(C[:, np.concatenate(X)]).reshape((X.shape[0], X.shape[1]*C.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(C[:, np.concatenate(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Project_and_concat() : \n",
    "    \"\"\"\n",
    "    The input is a vector x = (w_{t-1}, w_{t-2}, ..., w_{t-n+1})\n",
    "    For example, for n=4 the input vector x can be\n",
    "    (4, 2, 10)\n",
    "    where 4, 2 and 10 are the indexes of the corresponding words.\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_features,dict_size) : # V*m ou m*V\n",
    "        self.nb_features = nb_features\n",
    "        self.dict_size = dict_size\n",
    "        self.C = np.random.randn(dict_size,nb_features)\n",
    "        self.nb_params = nb_features * dict_size # Nombre de parametres de la couche\n",
    "        self.save_X = None # Parametre de sauvegarde des donnees\n",
    "    def set_params(self,params) : \n",
    "        # Permet de modifier les parametres de la couche, en entree, prend un vecteur de la taille self.nb_params\n",
    "        pass\n",
    "    def get_params(self) : \n",
    "        # Rend un vecteur de taille self.params qui contient les parametres de la couche\n",
    "        return np.ravel(self.C)\n",
    "    def forward(self,X) : \n",
    "        # calcul du forward, X est le vecteur des donnees d'entrees\n",
    "        self.save_X = np.copy(X)\n",
    "        return np.ravel(np.concatenate(C[X, :]))\n",
    "    def backward(self,grad_sortie) :  \n",
    "        # retropropagation du gradient sur la couche, \n",
    "        #grad_sortie est le vecteur du gradient en sortie\n",
    "        #Cette fonction rend :\n",
    "        #grad_local, un vecteur de taille self.nb_params qui contient le gradient par rapport aux parametres locaux\n",
    "        #grad_entree, le gradient en entree de la couche \n",
    "        grad_local=None\n",
    "        grad_entree=np.reshape(grad_sortie,(dict_size,nb_features))\n",
    "        return grad_local,grad_entree\n",
    "        \n",
    "# 2 étapes dans cette couche, les selections des lignes de C puis la concaténation\n",
    "# est ce que la selection des lignes de C rentre dans le calcul du dradient d'entree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.ones(4), np.concatenate(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.71828183   7.3890561   20.08553692]\n",
      " [ 54.59815003 148.4131591  403.42879349]]\n",
      "[[  2.71828183  54.59815003]\n",
      " [  7.3890561  148.4131591 ]\n",
      " [ 20.08553692 403.42879349]]\n",
      "[ 30.19287485 606.44010263]\n",
      "[[0.09003057 0.09003057]\n",
      " [0.24472847 0.24472847]\n",
      " [0.66524096 0.66524096]]\n",
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[1,2,3],[4,5,6]])\n",
    "b=np.array([2,3,4])\n",
    "\n",
    "a=np.exp(a)\n",
    "s=np.sum(a,axis=1)\n",
    "print(a)\n",
    "print(a.T)\n",
    "print(s)\n",
    "print(a.T/s)\n",
    "print(np.sum(a.T/s,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 7 9]\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[5 7 9]\n",
      "[[0.04742587 0.04742587 0.04742587]\n",
      " [0.95257413 0.95257413 0.95257413]]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[1,2,3],[4,5,6]])\n",
    "b=np.array([1,2,3])\n",
    "\n",
    "print(np.sum(a,axis=0))\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(np.sum(a,axis=0))\n",
    "\n",
    "print(np.exp(a)/np.sum(np.exp(a),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[0.04742587 0.04742587 0.04742587]\n",
      " [0.95257413 0.95257413 0.95257413]]\n"
     ]
    }
   ],
   "source": [
    "import Neuralword as Neur\n",
    "\n",
    "print(np.shape(a))\n",
    "print((Neur.ilogit(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=np.array([-5,-7,-10])\n",
    "np.argmax(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
